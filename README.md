# Getting-Started-with-Spark
 Intro to PySpark using climate data. Includes temperature &amp; CO₂ analysis with Google Colab + GCP Spark cluster.
# 🌍 Homework 2: Spark & Climate Change

## 🔎 Overview
This assignment uses **PySpark** to analyze global temperature and CO2 emissions data from 1750 to 2015. The goal is to identify climate trends using big data tools and cloud computing.

## 🛠 Tech Stack
- PySpark (via Google Colab)
- Google Cloud Dataproc
- Pandas, Matplotlib
- CSV climate datasets

## 📁 Files
- `homework2_climate_spark.ipynb`: Main notebook
- `GlobalLandTemperaturesByCountry.csv`: Temperature data
- `CO2Emissions.csv`: Emissions data
- `cluster_screenshot.png`: GCP cluster snapshot
- `homework2_reflection.pdf`: Summary + personal reflection
- python codes

## ✅ Key Tasks
- Set up Spark locally & on Google Cloud
- Analyzed hottest countries & temp change over time
- Merged CO2 data & computed correlation with temperature
- Reflected on environmental impact

## 📊 Output
- Strong positive correlation between CO2 and temperature
- Top 10 countries by temp increase identified

## 👤 Author
Shivani Tayade, MSBA @ UC Davis  
[LinkedIn](https://www.linkedin.com/in/shivanitayade1/)
