# Getting-Started-with-Spark
 Intro to PySpark using climate data. Includes temperature &amp; COâ‚‚ analysis with Google Colab + GCP Spark cluster.
# ğŸŒ Homework 2: Spark & Climate Change

## ğŸ” Overview
This assignment uses **PySpark** to analyze global temperature and CO2 emissions data from 1750 to 2015. The goal is to identify climate trends using big data tools and cloud computing.

## ğŸ›  Tech Stack
- PySpark (via Google Colab)
- Google Cloud Dataproc
- Pandas, Matplotlib
- CSV climate datasets

## ğŸ“ Files
- `homework2_climate_spark.ipynb`: Main notebook
- `GlobalLandTemperaturesByCountry.csv`: Temperature data
- `CO2Emissions.csv`: Emissions data
- `cluster_screenshot.png`: GCP cluster snapshot
- `homework2_reflection.pdf`: Summary + personal reflection
- python codes

## âœ… Key Tasks
- Set up Spark locally & on Google Cloud
- Analyzed hottest countries & temp change over time
- Merged CO2 data & computed correlation with temperature
- Reflected on environmental impact

## ğŸ“Š Output
- Strong positive correlation between CO2 and temperature
- Top 10 countries by temp increase identified

## ğŸ‘¤ Author
Shivani Tayade, MSBA @ UC Davis  
[LinkedIn](https://www.linkedin.com/in/shivanitayade1/)
