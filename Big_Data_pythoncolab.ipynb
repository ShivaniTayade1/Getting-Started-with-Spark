{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTu9ed4FWROD"
      },
      "outputs": [],
      "source": [
        "# Homework 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Java (required for Spark)\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download and extract Apache Spark 3.5.0 with Hadoop 3\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "# Install required Python packages\n",
        "!pip install -q findspark\n",
        "!pip install pyspark==3.5.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zOgFOdsWTGb",
        "outputId": "94c33bf9-88df-4592-a00b-8d7869775984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.5.5\n",
            "  Downloading pyspark-3.5.5.tar.gz (317.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.2/317.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark==3.5.5) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.5-py2.py3-none-any.whl size=317747862 sha256=5b5de84eeb2b7db37b338b31bf37303f687ae377c3be9baf29a0ecc7d616a353\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/7f/b4/0e68c6d8d89d2e582e5498ad88616c16d7c19028680e9d3840\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "  Attempting uninstall: pyspark\n",
            "    Found existing installation: pyspark 3.5.1\n",
            "    Uninstalling pyspark-3.5.1:\n",
            "      Successfully uninstalled pyspark-3.5.1\n",
            "Successfully installed pyspark-3.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Automatically detect Java version path (Java 8 or 11, whichever is installed)\n",
        "java_8_path = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "java_11_path = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "\n",
        "# Use whichever Java version is available\n",
        "if os.path.exists(java_8_path):\n",
        "    os.environ[\"JAVA_HOME\"] = java_8_path\n",
        "elif os.path.exists(java_11_path):\n",
        "    os.environ[\"JAVA_HOME\"] = java_11_path\n",
        "else:\n",
        "    raise EnvironmentError(\"No compatible Java version found.\")\n",
        "\n",
        "# Set Spark path\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n"
      ],
      "metadata": {
        "id": "d6IbCmFZXEQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Customize Spark Configuration\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Homework2_Spark_Chapter2\") \\\n",
        "    .master(\"local[2]\") \\\n",
        "    .config(\"spark.executor.memory\", \"1g\") \\\n",
        "    .config(\"spark.driver.memory\", \"1g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Print version to confirm setup\n",
        "print(\"Spark version:\", spark.version)\n",
        "\n",
        "# Print config settings\n",
        "for item in spark.sparkContext.getConf().getAll():\n",
        "    print(f\"{item[0]} = {item[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKgZ8vzoXJ3s",
        "outputId": "be7d25c6-8c0c-470a-a868-1b440e746958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark version: 3.5.0\n",
            "spark.app.name = Homework2_Spark_Chapter2\n",
            "spark.driver.port = 43905\n",
            "spark.app.submitTime = 1747325727518\n",
            "spark.app.id = local-1747325729910\n",
            "spark.executor.id = driver\n",
            "spark.sql.warehouse.dir = file:/content/spark-warehouse\n",
            "spark.driver.host = a762ce3337cb\n",
            "spark.driver.memory = 1g\n",
            "spark.driver.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
            "spark.executor.memory = 1g\n",
            "spark.rdd.compress = True\n",
            "spark.serializer.objectStreamReset = 100\n",
            "spark.submit.pyFiles = \n",
            "spark.submit.deployMode = client\n",
            "spark.app.startTime = 1747325727889\n",
            "spark.master = local[2]\n",
            "spark.ui.showConsoleProgress = true\n",
            "spark.executor.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "XCjQuMfEXKgn",
        "outputId": "40e9f48e-4c82-49a1-8e0e-1a7afaeb089d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2f250258-52e1-4560-9d1d-ba7da9c9b357\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2f250258-52e1-4560-9d1d-ba7da9c9b357\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2010-summary.csv to 2010-summary.csv\n",
            "Saving 2011-summary.csv to 2011-summary.csv\n",
            "Saving 2012-summary.csv to 2012-summary.csv\n",
            "Saving 2013-summary.csv to 2013-summary.csv\n",
            "Saving 2014-summary.csv to 2014-summary.csv\n",
            "Saving 2015-summary.csv to 2015-summary.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all the summary CSV files into one DataFrame\n",
        "df = spark.read.csv(\"*.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "2sJC48N_1y9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erig3FOa17XO",
        "outputId": "a2e314bf-ae1f-467c-b307-7eed7d8a5740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=1),\n",
              " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=264),\n",
              " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='India', count=69)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preview schema and data\n",
        "df.printSchema()\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOzdpU_mXSRh",
        "outputId": "1a93e9da-ff37-4612-b666-446ce33ff6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
            " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
            " |-- count: integer (nullable = true)\n",
            "\n",
            "+-----------------+-------------------+-----+\n",
            "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
            "+-----------------+-------------------+-----+\n",
            "|    United States|            Romania|    1|\n",
            "|    United States|            Ireland|  264|\n",
            "|    United States|              India|   69|\n",
            "|            Egypt|      United States|   24|\n",
            "|Equatorial Guinea|      United States|    1|\n",
            "+-----------------+-------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n",
        "df.describe().show()\n",
        "df.select(\"DEST_COUNTRY_NAME\", \"ORIGIN_COUNTRY_NAME\", \"count\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA06p6LLX-JA",
        "outputId": "a6a3da5f-7bb4-4c27-cb5d-2ec5a218ee02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+-------------------+------------------+\n",
            "|summary|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|             count|\n",
            "+-------+-----------------+-------------------+------------------+\n",
            "|  count|             1502|               1502|              1502|\n",
            "|   mean|             NULL|               NULL|1718.3189081225032|\n",
            "| stddev|             NULL|               NULL|22300.368619668898|\n",
            "|    min|      Afghanistan|        Afghanistan|                 1|\n",
            "|    max|         Zimbabwe|           Zimbabwe|            370002|\n",
            "+-------+-----------------+-------------------+------------------+\n",
            "\n",
            "+-----------------+-------------------+-----+\n",
            "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
            "+-----------------+-------------------+-----+\n",
            "|    United States|            Romania|    1|\n",
            "|    United States|            Ireland|  264|\n",
            "|    United States|              India|   69|\n",
            "|            Egypt|      United States|   24|\n",
            "|Equatorial Guinea|      United States|    1|\n",
            "+-----------------+-------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort(\"count\").explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eOEb7Pk2ZoM",
        "outputId": "b8079de5-3011-41db-fb6c-7ef424d72a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [count#672 ASC NULLS FIRST], true, 0\n",
            "   +- Exchange rangepartitioning(count#672 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=373]\n",
            "      +- FileScan csv [DEST_COUNTRY_NAME#670,ORIGIN_COUNTRY_NAME#671,count#672] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(6 paths)[file:/content/2010-summary.csv, file:/content/2011-summary.csv, file:/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:int>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
      ],
      "metadata": {
        "id": "6P3AqzAL22rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort(\"count\").take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q0y7xrK28uR",
        "outputId": "2246c5ef-c4d4-41d1-bbd8-4b8105013bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(DEST_COUNTRY_NAME='Equatorial Guinea', ORIGIN_COUNTRY_NAME='United States', count=1),\n",
              " Row(DEST_COUNTRY_NAME='Equatorial Guinea', ORIGIN_COUNTRY_NAME='United States', count=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"df\")\n"
      ],
      "metadata": {
        "id": "ybcgmuvJ5QJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "\n",
        "df.groupBy(\"DEST_COUNTRY_NAME\") \\\n",
        "  .count() \\\n",
        "  .orderBy(desc(\"count\")) \\\n",
        "  .show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jea1QxyaZ1bo",
        "outputId": "23204f13-1073-469a-d086-05ea96138dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+\n",
            "|DEST_COUNTRY_NAME|count|\n",
            "+-----------------+-----+\n",
            "|    United States|  736|\n",
            "|            Japan|    6|\n",
            "|       Cape Verde|    6|\n",
            "| French Polynesia|    6|\n",
            "|          Bolivia|    6|\n",
            "|         Pakistan|    6|\n",
            "|          Denmark|    6|\n",
            "| Marshall Islands|    6|\n",
            "|            Spain|    6|\n",
            "|           Panama|    6|\n",
            "+-----------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SQL version\n",
        "sqlWay = spark.sql(\"\"\"\n",
        "  SELECT DEST_COUNTRY_NAME, COUNT(1)\n",
        "  FROM  df\n",
        "  GROUP BY DEST_COUNTRY_NAME\n",
        "\"\"\")\n",
        "\n",
        "# DataFrame API version\n",
        "dataFrameWay = (\n",
        "    df\n",
        "      .groupBy(\"DEST_COUNTRY_NAME\")\n",
        "      .count()\n",
        ")\n",
        "\n",
        "# Show that the physical plans are identical\n",
        "sqlWay.explain()\n",
        "dataFrameWay.explain()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4vV2pgwx9Gs",
        "outputId": "d94e75ab-9960-4313-9805-d6b7458de213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[DEST_COUNTRY_NAME#670], functions=[count(1)])\n",
            "   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#670, 5), ENSURE_REQUIREMENTS, [plan_id=494]\n",
            "      +- HashAggregate(keys=[DEST_COUNTRY_NAME#670], functions=[partial_count(1)])\n",
            "         +- FileScan csv [DEST_COUNTRY_NAME#670] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(6 paths)[file:/content/2010-summary.csv, file:/content/2011-summary.csv, file:/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n",
            "\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[DEST_COUNTRY_NAME#670], functions=[count(1)])\n",
            "   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#670, 5), ENSURE_REQUIREMENTS, [plan_id=507]\n",
            "      +- HashAggregate(keys=[DEST_COUNTRY_NAME#670], functions=[partial_count(1)])\n",
            "         +- FileScan csv [DEST_COUNTRY_NAME#670] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(6 paths)[file:/content/2010-summary.csv, file:/content/2011-summary.csv, file:/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql (\"SELECT max(count) from df\").take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUMfEICS9nCn",
        "outputId": "608c1ef2-4ac7-46c6-9580-824494694a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(max(count)=370002)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# identical to the book’s line, followed by .take(1)\n",
        "spark.sql(\"SELECT MAX(count) FROM df\").take(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga3yS4ey9UWY",
        "outputId": "0f99e166-732e-4ed4-aa04-766eafac59f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(max(count)=370002)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import max as spark_max\n",
        "\n",
        "df.select(spark_max(\"count\")).take(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxH-xUr69WIh",
        "outputId": "d858b2e3-32d0-457e-802d-cacd58405fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(max(count)=370002)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top5_sql = spark.sql(\"\"\"\n",
        "  SELECT DEST_COUNTRY_NAME,\n",
        "         SUM(count) AS destination_total\n",
        "  FROM   flight_data_2015\n",
        "  GROUP  BY DEST_COUNTRY_NAME\n",
        "  ORDER  BY destination_total DESC\n",
        "  LIMIT  5\n",
        "\"\"\")\n",
        "top5_sql.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tuyn6sJ8MWN",
        "outputId": "eaf718ba-2535-481e-91a5-42f2861dc2ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------------+\n",
            "|DEST_COUNTRY_NAME|destination_total|\n",
            "+-----------------+-----------------+\n",
            "|    United States|          2348280|\n",
            "|           Canada|            49052|\n",
            "|           Mexico|            38075|\n",
            "|   United Kingdom|            10946|\n",
            "|            Japan|             9205|\n",
            "+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as spark_sum, desc\n",
        "\n",
        "top5_df = (\n",
        "    df.groupBy(\"DEST_COUNTRY_NAME\")\n",
        "      .agg(spark_sum(\"count\").alias(\"destination_total\"))\n",
        "      .orderBy(desc(\"destination_total\"))\n",
        "      .limit(5)\n",
        ")\n",
        "top5_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iMaEgNa9AsV",
        "outputId": "94cf4816-e44d-49d6-a0b7-34b105e2a037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------------+\n",
            "|DEST_COUNTRY_NAME|destination_total|\n",
            "+-----------------+-----------------+\n",
            "|    United States|          2348280|\n",
            "|           Canada|            49052|\n",
            "|           Mexico|            38075|\n",
            "|   United Kingdom|            10946|\n",
            "|            Japan|             9205|\n",
            "+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top5_sql.explain()   # physical plan\n",
        "top5_df.explain()    # identical physical plan\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mitn-eKj9DxD",
        "outputId": "8ce6078a-b43f-40f6-e484-f7a118aaf545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- TakeOrderedAndProject(limit=5, orderBy=[destination_total#765L DESC NULLS LAST], output=[DEST_COUNTRY_NAME#670,destination_total#765L])\n",
            "   +- HashAggregate(keys=[DEST_COUNTRY_NAME#670], functions=[sum(count#672)])\n",
            "      +- Exchange hashpartitioning(DEST_COUNTRY_NAME#670, 5), ENSURE_REQUIREMENTS, [plan_id=613]\n",
            "         +- HashAggregate(keys=[DEST_COUNTRY_NAME#670], functions=[partial_sum(count#672)])\n",
            "            +- FileScan csv [DEST_COUNTRY_NAME#670,count#672] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(6 paths)[file:/content/2010-summary.csv, file:/content/2011-summary.csv, file:/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,count:int>\n",
            "\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- TakeOrderedAndProject(limit=5, orderBy=[destination_total#788L DESC NULLS LAST], output=[DEST_COUNTRY_NAME#670,destination_total#788L])\n",
            "   +- HashAggregate(keys=[DEST_COUNTRY_NAME#670], functions=[sum(count#672)])\n",
            "      +- Exchange hashpartitioning(DEST_COUNTRY_NAME#670, 5), ENSURE_REQUIREMENTS, [plan_id=630]\n",
            "         +- HashAggregate(keys=[DEST_COUNTRY_NAME#670], functions=[partial_sum(count#672)])\n",
            "            +- FileScan csv [DEST_COUNTRY_NAME#670,count#672] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(6 paths)[file:/content/2010-summary.csv, file:/content/2011-summary.csv, file:/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,count:int>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"flights\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT DEST_COUNTRY_NAME, COUNT(*) as total_flights\n",
        "    FROM flights\n",
        "    GROUP BY DEST_COUNTRY_NAME\n",
        "    ORDER BY total_flights DESC\n",
        "    LIMIT 10\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUT3edWjZ9Vq",
        "outputId": "fc32625f-caf3-43cb-ed6d-38bf0536c6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------+\n",
            "|DEST_COUNTRY_NAME|total_flights|\n",
            "+-----------------+-------------+\n",
            "|    United States|          736|\n",
            "|      Philippines|            6|\n",
            "|           France|            6|\n",
            "|         Anguilla|            6|\n",
            "|             Fiji|            6|\n",
            "|         Paraguay|            6|\n",
            "|           Turkey|            6|\n",
            "|           Sweden|            6|\n",
            "|          Germany|            6|\n",
            "|           Guyana|            6|\n",
            "+-----------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "\n",
        "(\n",
        "    df.groupBy(\"DEST_COUNTRY_NAME\")\n",
        "      .sum(\"count\")\n",
        "      .withColumnRenamed(\"sum(count)\",\n",
        "                         \"destination_total\")\n",
        "      .sort(desc(\"destination_total\"))\n",
        "      .limit(5)\n",
        "      .show()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shk5Lhwk-UMO",
        "outputId": "90dea42f-71bb-4b59-d541-cec59a0b5533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------------+\n",
            "|DEST_COUNTRY_NAME|destination_total|\n",
            "+-----------------+-----------------+\n",
            "|    United States|          2348280|\n",
            "|           Canada|            49052|\n",
            "|           Mexico|            38075|\n",
            "|   United Kingdom|            10946|\n",
            "|            Japan|             9205|\n",
            "+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a year column by file source\n",
        "from pyspark.sql.functions import input_file_name, regexp_extract\n",
        "\n",
        "df_with_year = df.withColumn(\"source_file\", input_file_name())\n",
        "df_with_year = df_with_year.withColumn(\"year\", regexp_extract(\"source_file\", r'(\\d{4})', 1))\n",
        "\n",
        "df_with_year.select(\"year\", \"DEST_COUNTRY_NAME\", \"count\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-pC4xYgaAW0",
        "outputId": "f984582e-b7f8-4873-f308-e47bc9083c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------------+-----+\n",
            "|year|DEST_COUNTRY_NAME|count|\n",
            "+----+-----------------+-----+\n",
            "|2010|    United States|    1|\n",
            "|2010|    United States|  264|\n",
            "|2010|    United States|   69|\n",
            "|2010|            Egypt|   24|\n",
            "|2010|Equatorial Guinea|    1|\n",
            "+----+-----------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_year.groupBy(\"year\", \"DEST_COUNTRY_NAME\") \\\n",
        "  .sum(\"count\") \\\n",
        "  .orderBy(\"year\", desc(\"sum(count)\")) \\\n",
        "  .show()\n",
        "#this step has been executed to match the numbers for different years"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdNYsQAkaEgT",
        "outputId": "cb634573-f891-4119-cbba-e2b054703fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------------+----------+\n",
            "|year| DEST_COUNTRY_NAME|sum(count)|\n",
            "+----+------------------+----------+\n",
            "|2010|     United States|    384932|\n",
            "|2010|            Canada|      8271|\n",
            "|2010|            Mexico|      6200|\n",
            "|2010|    United Kingdom|      1629|\n",
            "|2010|           Germany|      1392|\n",
            "|2010|             Japan|      1383|\n",
            "|2010|Dominican Republic|      1109|\n",
            "|2010|            Brazil|       995|\n",
            "|2010|       The Bahamas|       903|\n",
            "|2010|          Colombia|       785|\n",
            "|2010|            France|       774|\n",
            "|2010|           Jamaica|       733|\n",
            "|2010|       South Korea|       683|\n",
            "|2010|       Netherlands|       586|\n",
            "|2010|       El Salvador|       519|\n",
            "|2010|        Costa Rica|       477|\n",
            "|2010|             China|       448|\n",
            "|2010|             Spain|       422|\n",
            "|2010|           Belgium|       408|\n",
            "|2010|          Honduras|       391|\n",
            "+----+------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#end of question2"
      ],
      "metadata": {
        "id": "iWEraDeA--KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "lMu2Tlt5aGkw",
        "outputId": "7b56b004-8ca8-4ef2-d5a4-d3c0f18b4895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-531d4999-40a8-4cee-8d26-3ce20133c815\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-531d4999-40a8-4cee-8d26-3ce20133c815\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving GlobalLandTemperatures_GlobalLandTemperaturesByCountry.csv to GlobalLandTemperatures_GlobalLandTemperaturesByCountry.csv\n",
            "Saving CO2 emissions per capita per country.csv to CO2 emissions per capita per country.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp = spark.read.csv(\"GlobalLandTemperatures_GlobalLandTemperaturesByCountry.csv\", header=True, inferSchema=True)\n",
        "df_temp.printSchema()\n",
        "df_temp.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sOJHmbAbbqj",
        "outputId": "766cf7d7-7c79-4692-d560-e8f346ff853f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- dt: date (nullable = true)\n",
            " |-- AverageTemperature: double (nullable = true)\n",
            " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            "\n",
            "+----------+------------------+-----------------------------+-------+\n",
            "|        dt|AverageTemperature|AverageTemperatureUncertainty|Country|\n",
            "+----------+------------------+-----------------------------+-------+\n",
            "|1743-11-01|4.3839999999999995|                        2.294|  Åland|\n",
            "|1743-12-01|              NULL|                         NULL|  Åland|\n",
            "|1744-01-01|              NULL|                         NULL|  Åland|\n",
            "|1744-02-01|              NULL|                         NULL|  Åland|\n",
            "|1744-03-01|              NULL|                         NULL|  Åland|\n",
            "+----------+------------------+-----------------------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On Canvas, you will find two datasets. The first dataset contains temperature\n",
        "data by countries. Date starts from 1750 for average land temperature and goes\n",
        "up to 2015. Answer the following questions:\n",
        "\n",
        "a. For which country and during what year, the highest average temperature\n",
        "was observed? [5 pts]\n",
        "\n",
        "b. Analyze the data by country over the years, and name which are the top\n",
        "10 countries with the biggest change in average temperature. [5 pts]"
      ],
      "metadata": {
        "id": "ps-CakpUc3jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a\n",
        "from pyspark.sql.functions import year, max\n",
        "\n",
        "df_temp = df_temp.withColumn(\"Year\", year(\"dt\"))\n",
        "df_temp.createOrReplaceTempView(\"temp\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT Country, Year, AVG(AverageTemperature) as AvgTemp\n",
        "    FROM temp\n",
        "    GROUP BY Country, Year\n",
        "    ORDER BY AvgTemp DESC\n",
        "    LIMIT 1\n",
        "\"\"\").show()\n",
        "\n",
        "print(\"for country Djibouti in year 2013, the highest temperature was observed at 30.7447\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXyyPHNubono",
        "outputId": "0b5d6f16-c44c-4de9-e304-dc088c7e98db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+------------------+\n",
            "| Country|Year|           AvgTemp|\n",
            "+--------+----+------------------+\n",
            "|Djibouti|2013|30.744749999999996|\n",
            "+--------+----+------------------+\n",
            "\n",
            "for country Djibouti in year 2013, the highest temperature was observed at 30.7447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "w_first = Window.partitionBy(\"Country\").orderBy(\"Year\")\n",
        "w_last  = Window.partitionBy(\"Country\").orderBy(F.desc(\"Year\"))\n",
        "\n",
        "first_last = (\n",
        "    df_country_year\n",
        "      .withColumn(\"FirstYear\",     F.first(\"Year\").over(w_first))\n",
        "      .withColumn(\"FirstYearTemp\", F.first(\"AvgTemp\").over(w_first))\n",
        "      .withColumn(\"LastYear\",      F.first(\"Year\").over(w_last))\n",
        "      .withColumn(\"LastYearTemp\",  F.first(\"AvgTemp\").over(w_last))\n",
        "      .select(\"Country\", \"FirstYear\", \"FirstYearTemp\",\n",
        "              \"LastYear\",  \"LastYearTemp\")\n",
        "      .distinct()                             # one row per country\n",
        "      .withColumn(\"TempChange\",\n",
        "                  F.col(\"LastYearTemp\") - F.col(\"FirstYearTemp\"))\n",
        ")\n",
        "\n",
        "# 3.  Top-10 warm-ups\n",
        "top10_change = (\n",
        "    first_last.orderBy(F.desc(\"TempChange\"))\n",
        "              .limit(10)\n",
        ")\n",
        "print(\"Top-10 countries with the largest overall rise in average land temperature:\")\n",
        "top10_change.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB9rrfV-L_0n",
        "outputId": "84dd10fd-1db9-4c33-e83c-eece1c67119f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-10 countries with the largest overall rise in average land temperature:\n",
            "+----------+---------+------------------+--------+------------------+------------------+\n",
            "|Country   |FirstYear|FirstYearTemp     |LastYear|LastYearTemp      |TempChange        |\n",
            "+----------+---------+------------------+--------+------------------+------------------+\n",
            "|Kuwait    |1839     |12.02             |2013    |27.273375         |15.253375000000002|\n",
            "|Ukraine   |1743     |1.898             |2013    |10.913499999999999|9.0155            |\n",
            "|Azerbaijan|1808     |5.235             |2013    |14.173875         |8.938875          |\n",
            "|Moldova   |1743     |3.4150000000000005|2013    |11.9605           |8.545499999999999 |\n",
            "|Georgia   |1779     |2.3055            |2013    |10.686625         |8.381124999999999 |\n",
            "|Syria     |1808     |12.096000000000002|2013    |20.021124999999998|7.925124999999996 |\n",
            "|Macedonia |1743     |5.431             |2013    |13.260124999999999|7.829124999999999 |\n",
            "|Romania   |1743     |3.89              |2013    |11.6455           |7.7555            |\n",
            "|Serbia    |1743     |5.151             |2013    |12.843625         |7.692625          |\n",
            "|Finland   |1743     |-3.571            |2013    |4.064125000000001 |7.635125          |\n",
            "+----------+---------+------------------+--------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2PART"
      ],
      "metadata": {
        "id": "T7mCBAdLbR87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "co2_path = \"/content/CO2 emissions per capita per country.csv\"\n",
        "df_co2_raw = spark.read.option(\"header\", True).csv(co2_path)"
      ],
      "metadata": {
        "id": "S4n5yB9Fc8dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "co2_raw = (\n",
        "    spark.read.option(\"header\", True)\n",
        "              .option(\"inferSchema\", True)\n",
        "              .csv(co2_path)\n",
        ")\n",
        "\n",
        "years = [str(y) for y in range(1960, 2015)]               # 1960-2014\n",
        "expr = (\n",
        "    \"stack(\" + str(len(years)) + \", \" +\n",
        "    \", \".join([f\"'{y}', `{y}`\" for y in years]) +\n",
        "    \") as (Year, CO2_per_capita)\"\n",
        ")\n",
        "\n",
        "co2_long = (\n",
        "    co2_raw.selectExpr(\"`Country Name` as Country\", expr)\n",
        "           .filter(F.col(\"CO2_per_capita\").isNotNull())\n",
        "           .withColumn(\"Year\", F.col(\"Year\").cast(\"int\"))\n",
        ")\n",
        "\n",
        "co2_long.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWGnaw8SeLle",
        "outputId": "ec9a15bb-1b89-4a6a-d51f-cc6ac43ae2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------------+\n",
            "|Country|Year|CO2_per_capita|\n",
            "+-------+----+--------------+\n",
            "|Aruba  |1986|2.868319392   |\n",
            "|Aruba  |1987|7.235198033   |\n",
            "|Aruba  |1988|10.02617921   |\n",
            "|Aruba  |1989|10.6347326    |\n",
            "|Aruba  |1990|26.37450321   |\n",
            "+-------+----+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_60_14 = (\n",
        "    df_country_year.filter((F.col(\"Year\") >= 1960) & (F.col(\"Year\") <= 2014))\n",
        ")\n",
        "\n",
        "merged = (\n",
        "    temp_60_14.join(co2_long, on=[\"Country\", \"Year\"])\n",
        "              .select(\"Country\", \"Year\",\n",
        "                      \"AvgTemp\", \"CO2_per_capita\")\n",
        ")\n",
        "\n",
        "print(f\"Rows after merge (1960-2014)  ➜  {merged.count()}\")\n",
        "merged.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8IW5-2CdKlQ",
        "outputId": "541f3d2a-b4a4-43ed-9011-a9968e9fef80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows after merge (1960-2014)  ➜  7844\n",
            "+-----------+----+------------------+--------------+\n",
            "|Country    |Year|AvgTemp           |CO2_per_capita|\n",
            "+-----------+----+------------------+--------------+\n",
            "|Afghanistan|1971|14.823500000000001|0.166042044   |\n",
            "|Afghanistan|1977|14.805416666666668|0.182963616   |\n",
            "|Afghanistan|1979|14.262083333333335|0.168376671   |\n",
            "|Afghanistan|1980|14.887333333333332|0.132858608   |\n",
            "|Afghanistan|1984|14.245833333333332|0.234987713   |\n",
            "+-----------+----+------------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PARTB\n",
        "corr_val = merged.stat.corr(\"AvgTemp\", \"CO2_per_capita\")\n",
        "print(f\"Pearson correlation (AvgTemp  vs  CO₂ per-capita)  =  {corr_val:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIWjgqfZdNQx",
        "outputId": "8f759838-0a00-4409-b4c3-735feb94cab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson correlation (AvgTemp  vs  CO₂ per-capita)  =  -0.2345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CORELATION PER COUNTRY\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "corr_by_country = (\n",
        "    merged.groupBy(\"Country\")\n",
        "          .agg(F.corr(\"AvgTemp\", \"CO2_per_capita\").alias(\"Corr\"))\n",
        "          .orderBy(F.desc(\"Corr\"))\n",
        ")\n",
        "\n",
        "corr_by_country.show(5, truncate=False)  # top 5 positive correlations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6BjVd4ydUTd",
        "outputId": "23770462-15c0-4d69-cf82-f8afbfee2461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+------------------+\n",
            "|Country               |Corr              |\n",
            "+----------------------+------------------+\n",
            "|Oman                  |0.792979699666993 |\n",
            "|British Virgin Islands|0.7912382775273427|\n",
            "|Dominica              |0.7690842486975374|\n",
            "|Mauritius             |0.7612099341266811|\n",
            "|Pakistan              |0.759414849034336 |\n",
            "+----------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aatJrG-3dw_L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}